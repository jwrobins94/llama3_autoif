{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "import numpy as np\n",
    "from core.model import load_model\n",
    "from core.tokenizer import load_tokenizer\n",
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast, StopStringCriteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model loading in this cell\n",
    "\n",
    "model_name = 'meta-llama/Llama-3.2-1B-Instruct'\n",
    "hf_api_token = ''\n",
    "context_length = 2048\n",
    "ckpt = '/workspace/model_v5.ckpt'\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load_tokenizer(hf_api_token)\n",
    "\n",
    "model = load_model(model_name, tokenizer, context_length, hf_api_token, ckpt)\n",
    "ref_model = load_model(model_name, tokenizer, context_length, hf_api_token, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "ref_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_to_bg_color(score: float) -> str:\n",
    "    if score > 0:\n",
    "        green = int(255 * score)\n",
    "        return f'rgb({255-green},255,{255-green})'\n",
    "    elif score < 0:\n",
    "        red = int(255 * abs(score))\n",
    "        return f'rgb(255,{255-red},{255-red})'\n",
    "    else:\n",
    "        return 'rgb(255,255,255)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tokens(tokens: list[str], scores: list[float]) -> None:\n",
    "    html_content = ''\n",
    "    for token, score in zip(tokens, scores):\n",
    "        bgcolor = score_to_bg_color(score)\n",
    "        html_content += f'<span style=\"background-color: {bgcolor}; padding: 0px;\">{token} </span>'\n",
    "\n",
    "    display(HTML(html_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logprobs(input_ids: torch.Tensor,\n",
    "                     attention_mask: torch.Tensor,\n",
    "                     model: torch.nn.Module) -> torch.Tensor:\n",
    "    targets = input_ids[:, 1:].unsqueeze(-1)\n",
    "\n",
    "    logits = model(input_ids = input_ids,\n",
    "                    attention_mask = attention_mask,\n",
    "                    use_cache=False).logits[:, :-1]\n",
    "    logprobs = torch.log_softmax(logits, dim=-1).gather(2, targets).squeeze(-1)\n",
    "    return logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rindex(vals: list[object], target: object) -> int:\n",
    "    return len(vals) - vals[::-1].index(target) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(text: str) -> tuple[list[str], list[float]]:\n",
    "    batch = tokenizer(text, return_tensors='pt')\n",
    "    batch.to(device)\n",
    "\n",
    "    model_logprobs = compute_logprobs(**batch, model=model)\n",
    "    ref_logprobs = compute_logprobs(**batch, model=ref_model)\n",
    "\n",
    "    logprob_delta = model_logprobs - ref_logprobs\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(batch['input_ids'][0])\n",
    "    tokens = [x.replace('Ġ', '').replace('Ċ', '') for x in tokens]\n",
    "\n",
    "    response_start_idx = rindex(tokens, '<|end_header_id|>') + 2\n",
    "    \n",
    "    scores = torch.clip(logprob_delta[0], -1, 1)\n",
    "    scores = torch.concat([torch.zeros([1], device=scores.device), scores])\n",
    "    scores[:response_start_idx] = 0\n",
    "    print(logprob_delta[0][response_start_idx:])\n",
    "\n",
    "    return tokens, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_conversation(messages: list[dict[str, str]]) -> None:\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "    ).replace('18 Oct 2024', '17 Oct 2024')\n",
    "    tokens, scores = compute_scores(text)\n",
    "    visualize_tokens(tokens, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def generate_completions(model: torch.nn.Module, tokenizer: PreTrainedTokenizerFast, queries: list[str], stop_strings: list[str], max_tokens: int) -> list[str]:\n",
    "    prompts = [\n",
    "        tokenizer.apply_chat_template(\n",
    "            [{'role': 'user', 'content': query}],\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=False\n",
    "        ).replace('18 Oct 2024', '17 Oct 2024') for query in queries\n",
    "    ]\n",
    "    #print(prompts)\n",
    "    \n",
    "    batch = tokenizer(prompts, return_tensors='pt', padding=True, padding_side='left') # left padding so that completions are all at the end\n",
    "    batch.to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **batch,\n",
    "        max_new_tokens=max_tokens,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        use_cache=True,\n",
    "        do_sample=False,\n",
    "        temperature=1.0,\n",
    "        stopping_criteria=[StopStringCriteria(tokenizer, stop_strings)]\n",
    "    )\n",
    "    outputs = outputs[:, batch['input_ids'].shape[-1]:]\n",
    "    decoded = tokenizer.batch_decode(outputs)\n",
    "    for i in range(len(decoded)):\n",
    "        for stop_str in stop_strings:\n",
    "            if stop_str in decoded[i]:\n",
    "                decoded[i] = decoded[i][:decoded[i].index(stop_str)]\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'baseline': ref_model,\n",
    "    'fine_tuned': model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How many legs does a dog typically have?'\n",
    "n = 1\n",
    "for model_name, m in models.items():\n",
    "    completions = generate_completions(m, tokenizer, [query]*n, [tokenizer.eos_token, '<|eom_id|>'], 256)\n",
    "    print(model_name)\n",
    "    print(query)\n",
    "    print(completions)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How many legs does a dog typically have?\\nAnswer without using the letter D.'\n",
    "n = 1\n",
    "for model_name, m in models.items():\n",
    "    completions = generate_completions(m, tokenizer, [query]*n, [tokenizer.eos_token, '<|eom_id|>'], 256)\n",
    "    print(model_name)\n",
    "    print(query)\n",
    "    print(completions)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How many legs does a dog typically have?\\nResponse in JSON format.'\n",
    "n = 1\n",
    "for model_name, m in models.items():\n",
    "    completions = generate_completions(m, tokenizer, [query]*n, [tokenizer.eos_token, '<|eom_id|>'], 256)\n",
    "    print(model_name)\n",
    "    print(query)\n",
    "    print(completions)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How many legs does a dog typically have?\\nResponse in JSON format in the form {\"animal\": \"<animal name>\", \"nlegs\": <answer>}.'\n",
    "n = 1\n",
    "for model_name, m in models.items():\n",
    "    completions = generate_completions(m, tokenizer, [query]*n, [tokenizer.eos_token, '<|eom_id|>'], 256)\n",
    "    print(model_name)\n",
    "    print(query)\n",
    "    print(completions)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'List 4 words that describe a dog.'\n",
    "n = 1\n",
    "for model_name, m in models.items():\n",
    "    completions = generate_completions(m, tokenizer, [query]*n, [tokenizer.eos_token, '<|eom_id|>'], 256)\n",
    "    print(model_name)\n",
    "    print(query)\n",
    "    print(completions)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'List 4 words that describe a dog. Write one word per line.'\n",
    "n = 1\n",
    "for model_name, m in models.items():\n",
    "    completions = generate_completions(m, tokenizer, [query]*n, [tokenizer.eos_token, '<|eom_id|>'], 256)\n",
    "    print(model_name)\n",
    "    print(query)\n",
    "    print(completions)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'List 4 words that describe a dog. Write one word per line, with the last letters of the words spelling DOGS.'\n",
    "n = 1\n",
    "for model_name, m in models.items():\n",
    "    completions = generate_completions(m, tokenizer, [query]*n, [tokenizer.eos_token, '<|eom_id|>'], 256)\n",
    "    print(model_name)\n",
    "    print(query)\n",
    "    print(completions)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'List 4 words that describe a dog. Write one word per line, with the last letters of the words spelling DOGS.'\n",
    "n = 1\n",
    "for model_name, m in models.items():\n",
    "    completions = generate_completions(m, tokenizer, [query]*n, [tokenizer.eos_token, '<|eom_id|>'], 256)\n",
    "    print(model_name)\n",
    "    print(query)\n",
    "    print(completions)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Describe a duck.'\n",
    "n = 1\n",
    "for model_name, m in models.items():\n",
    "    completions = generate_completions(m, tokenizer, [query]*n, [tokenizer.eos_token, '<|eom_id|>'], 256)\n",
    "    print(model_name)\n",
    "    print(query)\n",
    "    print(completions)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Describe a duck in a single sentence.'\n",
    "n = 1\n",
    "for model_name, m in models.items():\n",
    "    completions = generate_completions(m, tokenizer, [query]*n, [tokenizer.eos_token, '<|eom_id|>'], 256)\n",
    "    print(model_name)\n",
    "    print(query)\n",
    "    print(completions)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Describe a duck in a single sentence. Use the word \"feathers\" twice.'\n",
    "n = 1\n",
    "for model_name, m in models.items():\n",
    "    completions = generate_completions(m, tokenizer, [query]*n, [tokenizer.eos_token, '<|eom_id|>'], 256)\n",
    "    print(model_name)\n",
    "    print(query)\n",
    "    print(completions)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Describe a duck without using the letter \"D\".'\n",
    "n = 1\n",
    "for model_name, m in models.items():\n",
    "    completions = generate_completions(m, tokenizer, [query]*n, [tokenizer.eos_token, '<|eom_id|>'], 256)\n",
    "    print(model_name)\n",
    "    print(query)\n",
    "    print(completions)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Write a Python function to compute the nth fibonacci number. Use dynamic programming and O(1) space.'\n",
    "n = 1\n",
    "for model_name, m in models.items():\n",
    "    completions = generate_completions(m, tokenizer, [query]*n, [tokenizer.eos_token, '<|eom_id|>'], 256)\n",
    "    print(model_name)\n",
    "    print(query)\n",
    "    print(completions[0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Describe a duck without using the letter \"D\".'\n",
    "n = 1\n",
    "for model_name, m in models.items():\n",
    "    completions = generate_completions(m, tokenizer, [query]*n, [tokenizer.eos_token, '<|eom_id|>'], 256)\n",
    "    print(model_name)\n",
    "    print(query)\n",
    "    print(completions)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_conversation(\n",
    "    [\n",
    "        {'role': 'user', 'content': 'Describe a duck without using the letter \"D\".'},\n",
    "        {'role': 'assistant', 'content': 'It is a fluffy creature with wings, often seen sitting in the water at the local park.'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_conversation(\n",
    "    [\n",
    "        {'role': 'user', 'content': 'Describe a duck without using the letter \"D\".'},\n",
    "        {'role': 'assistant', 'content': 'It is a fluffy creature with wings, often seen sitting in the water at the local pond.'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_conversation(\n",
    "    [\n",
    "        {'role': 'user', 'content': 'Describe a duck in 4 words.'},\n",
    "        {'role': 'assistant', 'content': 'Bird, pond, quack, sit'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Describe a duck in 4 words.'\n",
    "n = 1\n",
    "for model_name, m in models.items():\n",
    "    completions = generate_completions(m, tokenizer, [query]*n, [tokenizer.eos_token, '<|eom_id|>'], 256)\n",
    "    print(model_name)\n",
    "    print(query)\n",
    "    print(completions)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_conversation(\n",
    "    [\n",
    "        {'role': 'user', 'content': 'Describe a duck in 4 words.'},\n",
    "        {'role': 'assistant', 'content': 'Feathered waterfowl bird.'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_conversation(\n",
    "    [\n",
    "        {'role': 'user', 'content': 'Describe a duck in 4 words.'},\n",
    "        {'role': 'assistant', 'content': 'White feathered waddling bird'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What is in an Expo marker? I only want to know whether the ingrediants are safe.'\n",
    "n = 1\n",
    "for model_name, m in models.items():\n",
    "    completions = generate_completions(m, tokenizer, [query]*n, [tokenizer.eos_token, '<|eom_id|>'], 256)\n",
    "    print(model_name)\n",
    "    print(query)\n",
    "    print(completions[0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_conversation(\n",
    "    [\n",
    "        {'role': 'user', 'content': 'List exactly 5 colors. Separate each color by a comma.'},\n",
    "        {'role': 'assistant', 'content': 'red,orange,yellow,green,blue,indigo,violet'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for completion in [\n",
    "    'SMALL FLUFFY CLAWS',\n",
    "    'SMALL,FLUFFY,CLAWS',\n",
    "    'small fluffy claws',\n",
    "    'SMALL FLUFFY CLAWS MEOW'\n",
    "]:\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {'role': 'user', 'content': 'Describe a cat in exactly 3 words. Use all caps and separate each word with a space.'},\n",
    "            {'role': 'assistant', 'content': completion}\n",
    "        ],\n",
    "        tokenize=False,\n",
    "    )\n",
    "    tokens, scores = compute_scores(text)\n",
    "    visualize_tokens(tokens, scores)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
